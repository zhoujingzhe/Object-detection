{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "Thie file is to evaluate the model.  \n",
    "<span style=\"color:red\">Warning: our model is trained on multi-gpu server, if you don't have multi-gpu on your server, you should cancel the two lines, 'model = multi_gpu_model(model, gpus=4)'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "import keras.models\n",
    "import xml.etree.ElementTree as ET\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import os\n",
    "from settings import setting\n",
    "import cv2\n",
    "from keras.utils.np_utils import to_categorical\n",
    "img_count = 0\n",
    "############################################\n",
    "import Util_V2 as U\n",
    "if setting['model'] == \"DecayByBatch\":\n",
    "    optimizer = Adam(lr=setting[\"lr\"])\n",
    "elif setting['model'] == \"DecayByEpoch\":\n",
    "    optimizer = Adam(lr=setting[\"lr\"])\n",
    "if setting['loss'] == 'Loss_v2':\n",
    "    lossFunction = U.Loss_v2\n",
    "elif setting['loss'] == 'Loss_v3':\n",
    "    lossFunction = U.Loss_v3\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data and Test the prediction\n",
    "LOAD_IMAGE is a tool function for loading the image into binary form.  \n",
    "readXML is a tool function for reading the label information with respect to a image.  \n",
    "load_DATA is to load all images into a path.  \n",
    "Matching is a judgement wether the bounding boxes predicted by the model is correctly hitting the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOAD_IMAGE(path = 'C:/Users/ZJZ20\\Downloads/DeepLearnData/img_0.jpg'):\n",
    "    image1 = load_img(path)\n",
    "    train_example = img_to_array(image1, data_format='channels_first')\n",
    "    img = array_to_img(train_example, data_format='channels_first')\n",
    "#    img.show()\n",
    "    train_example = train_example.transpose()\n",
    "    return train_example\n",
    "\n",
    "\n",
    "def readXML(f='C:/Users/ZJZ20\\Downloads/DeepLearnData/img_0.xml'):\n",
    "    mapped = {}\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    for elem in root:\n",
    "        if len(elem) == 0:\n",
    "            mapped[elem.tag] = elem.text\n",
    "        for subelem in elem:\n",
    "            if len(subelem) == 0:\n",
    "                mapped[subelem.tag] = subelem.text\n",
    "            for sub2elem in subelem:\n",
    "                if len(sub2elem) == 0:\n",
    "                    mapped[sub2elem.tag] = sub2elem.text\n",
    "    xmax = int(mapped['xmax'])\n",
    "    xmin = int(mapped['xmin'])\n",
    "    ymax = int(mapped['ymax'])\n",
    "    ymin = int(mapped['ymin'])\n",
    "    C_index = int(mapped['name'][1])\n",
    "    yTrue = np.zeros((19, 14, 7), dtype='float32')\n",
    "    yTrue[:, :] = [xmax, xmin, ymax, ymin, 0, 0, C_index]\n",
    "    return yTrue\n",
    "\n",
    "\n",
    "def load_DATA(srcDir):\n",
    "    fileCount = len([name for name in os.listdir(srcDir) if name.endswith(\".xml\")])\n",
    "    train_data = np.empty(shape=[fileCount, 640, 480, 3], dtype='float32')\n",
    "    train_label = np.empty(shape=[fileCount, 19, 14, 7], dtype='float32')\n",
    "\n",
    "    count = 0\n",
    "    for filename in os.listdir(srcDir):\n",
    "        if not filename.endswith(\".xml\"): continue\n",
    "        count += 1\n",
    "        xmlFile = srcDir + \"/\" + filename\n",
    "        print(xmlFile)\n",
    "        imgFile = xmlFile.replace(\".xml\", \".jpg\")\n",
    "        print(imgFile)\n",
    "        train_data[count - 1] = LOAD_IMAGE(imgFile)\n",
    "        train_label[count - 1] = readXML(xmlFile)\n",
    "    train_label[:, :, :, 4] = np.arange(0, 19, 1).reshape(19, 1)\n",
    "    train_label[:, :, :, 5] = np.arange(0, 14, 1).reshape(1, 14)\n",
    "    return [train_data, train_label]\n",
    "\n",
    "\n",
    "# there is a hyperparameter, to judge if the boxes hit the targets.\n",
    "# the rule is if the ratio of the overlap area is more than a threshold, \n",
    "# in comparison with the union areas between the actual box and the predicted box.\n",
    "# we think it is correctly fit.\n",
    "# the threshold is 0.7 manually devised by hands.\n",
    "\n",
    "def Matching(x1_pred, y1_pred, x2_pred, y2_pred, x_max_true, x_min_true, y_max_true, y_min_true):\n",
    "    intersect_x1 = K.maximum(x1_pred, x_min_true)\n",
    "    intersect_y1 = K.maximum(y1_pred, y_min_true)\n",
    "    intersect_x2 = K.minimum(x2_pred, x_max_true)\n",
    "    intersect_y2 = K.minimum(y2_pred, y_max_true)\n",
    "\n",
    "    area_1 = (x2_pred - x1_pred) * (y2_pred - y1_pred)\n",
    "    area_2 = (x_max_true - x_min_true) * (y_max_true - y_min_true)\n",
    "\n",
    "    intersect_area = (intersect_x2 - intersect_x1) * (intersect_y2 - intersect_y1)\n",
    "\n",
    "    IOU = intersect_area / (area_1 + area_2 - intersect_area)\n",
    "    matching = K.greater_equal(IOU, 0.7)\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to compute the IOU (intersection over union)\n",
    "\n",
    "<img style=\"display: block; margin: 0 auto;\"\n",
    "     src=\"figures/IOU Compute.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The custom two metric for evaluating the performance on the location and classification\n",
    "Testing_Performance_location is a self-design metric to output the accuracy of bounding boxes.  \n",
    "Testing_Performance_classification is a custom metric to output the accuracy of classified behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing_Performance_location(y_true, y_pred):\n",
    "    # acquire the top five predictions in each image\n",
    "    boxes, classes, scores = U.generating_consequences(y_pred)\n",
    "    \n",
    "    # transform the coordinates from the sliding window coordinate to the image coordinate\n",
    "    x1, y1, x2, y2 = U.transform_to_coordinate(boxes[:, :, 0], boxes[:, :, 1], boxes[:, :, 2], boxes[:, :, 3])\n",
    "    x1 = K.reshape(x=x1, shape=(setting['batch_size'], -1, 1))\n",
    "    x2 = K.reshape(x=x2, shape=(setting['batch_size'], -1, 1))\n",
    "    y1 = K.reshape(x=y1, shape=(setting['batch_size'], -1, 1))\n",
    "    y2 = K.reshape(x=y2, shape=(setting['batch_size'], -1, 1))\n",
    "    Boxes = K.concatenate([x1, y1, x2, y2])\n",
    "    x1_pred = Boxes[:, :, 0]\n",
    "    y1_pred = Boxes[:, :, 1]\n",
    "    x2_pred = Boxes[:, :, 2]\n",
    "    y2_pred = Boxes[:, :, 3]\n",
    "\n",
    "    # obtain the actual coordinates in each image\n",
    "    x_max_true = y_true[:, 0, 0, 0]\n",
    "    x_min_true = y_true[:, 0, 0, 1]\n",
    "    y_max_true = y_true[:, 0, 0, 2]\n",
    "    y_min_true = y_true[:, 0, 0, 3]\n",
    "    x_max_true = K.reshape(x_max_true, (setting['batch_size'], 1))\n",
    "    x_min_true = K.reshape(x_min_true, (setting['batch_size'], 1))\n",
    "    y_max_true = K.reshape(y_max_true, (setting['batch_size'], 1))\n",
    "    y_min_true = K.reshape(y_min_true, (setting['batch_size'], 1))\n",
    "    \n",
    "    # return the result of if the bounding boxes are successed in the location prediciton\n",
    "    IOU = Matching(x1_pred=x1_pred, y1_pred=y1_pred, x2_pred=x2_pred, y2_pred=y2_pred, x_max_true=x_max_true,\n",
    "                   x_min_true=x_min_true, y_max_true=y_max_true, y_min_true=y_min_true)\n",
    "    IOU = K.cast(IOU, 'float32')\n",
    "    mat = K.max(IOU, axis=-1)\n",
    "    \n",
    "    # Computing the accuracy of bounding boxes hitting the targets\n",
    "    return K.cast(tf.count_nonzero(input_tensor=mat), 'float32') / setting['batch_size']\n",
    "\n",
    "def Testing_Performance_classification(y_true, y_pred):\n",
    "    # acquire the top five predictions in each image\n",
    "    boxes, classes, scores = U.generating_consequences(y_pred)\n",
    "    \n",
    "    # acquire the actual class for each image\n",
    "    groundtrue_class = y_true[:, 0, 0, 6]\n",
    "    groundtrue_class = K.cast(groundtrue_class, 'int64')\n",
    "    groundtrue_class = K.reshape(groundtrue_class, (setting['batch_size'], 1))\n",
    "    \n",
    "    # judge if the classified consquences is correct\n",
    "    classification_loss = K.equal(classes, groundtrue_class)\n",
    "    classification_loss = K.cast(x=classification_loss, dtype='float32')\n",
    "    class_match = K.max(classification_loss, axis=-1)\n",
    "    \n",
    "    # compute the accuracy on the classification\n",
    "    return K.cast(tf.count_nonzero(input_tensor=class_match), 'float32') / setting['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # loading an existed model\n",
    "    model = load_model(str(setting[\"weight_file\"]+'.h5'), custom_objects={setting[\"loss\"]: lossFunction})\n",
    "#     model = multi_gpu_model(model, gpus=4)\n",
    "    srcDir = \"group2/images/1\"\n",
    "    print(\"+++ run: \" + srcDir + \" \" + str(datetime.now()) + \"+++\")\n",
    "    \n",
    "    # recompile the model with the two self-design metrics\n",
    "    model.compile(optimizer=optimizer, loss=lossFunction, metrics=[Testing_Performance_location, Testing_Performance_classification])\n",
    "    \n",
    "    # loading the data\n",
    "    train_data, train_label = load_DATA(srcDir=srcDir)\n",
    "    one_hot_encoding = to_categorical(y=train_label[:, :, :, 6], num_classes=10)\n",
    "    train_label = np.concatenate((train_label, one_hot_encoding), axis = -1)\n",
    "    \n",
    "    # evaluate it and output results\n",
    "    loss_and_metrics = model.evaluate(x=train_data, y=train_label, batch_size=setting['batch_size'])\n",
    "    print('location_accuracy', loss_and_metrics[1])\n",
    "    print('classification_accuracy', loss_and_metrics[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
