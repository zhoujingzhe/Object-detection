{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util_V2 package\n",
    "This package obtains some tools for computing the loss function of loss_v2 and loss_v3  \n",
    "The block below is to import packages we use and set hyperparameters from scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import keras.backend as K\n",
    "from keras.activations import softmax\n",
    "from keras.losses import categorical_crossentropy\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from settings import setting\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "# weight_Classification_loss is the important factors of loss on classification\n",
    "# weight_Object_loss is the important factors of loss on Object detection\n",
    "# weight_Localization_loss is the important factors of loss on Localizations of objets\n",
    "# initial_lr is the initial learning rate that is a fixed value 0.01\n",
    "# Hdecay is the decay value\n",
    "# _epsilon is a extreme low value to avoid being 0 \n",
    "# lr_minimum_rate_times is minimum times that the learning rate can be decreased by\n",
    "###########################################################################\n",
    "weight_Classification_loss = setting[\"weight_Classification_loss\"]\n",
    "weight_Object_loss = setting[\"weight_Object_loss\"]\n",
    "weight_Localization_loss = setting[\"weight_Localization_loss\"]\n",
    "_batch_size = setting['batch_size']\n",
    "_epoch = 0\n",
    "initial_lr = 0.01\n",
    "Hdecay = setting[\"decay\"]\n",
    "lr_minimum_rate = 60.0\n",
    "_epsilon = K.epsilon()\n",
    "_epsilon = K.cast(_epsilon, 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate update mechanism in Keras\n",
    "new_lr = lr * 1.0 / (1.0 + decay * iterations)  \n",
    "At here, we try two different decay mechanism to figure out which is fit for our models, and attempt to see what's kind of the influence from each decay.  \n",
    "At the same time, to avoid learning rate being faded after many iterations, we define a low bound of learning rate that is the initial learning rate divided by lr_minimum_rate_times (the minimum times the learning rate can be reduced comparing with initial value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom learning rate decay function\n",
    "# the learning rate decay in each epoch end and print the new learning rate\n",
    "# beside, if the learning rate has been reduced to a minimum  times, this process stops\n",
    "class DecayByEpoch(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, log=[]):\n",
    "        global Hdecay\n",
    "        new_lr = initial_lr * 1.0 / (1.0 + Hdecay * epoch)\n",
    "        if initial_lr / new_lr > lr_minimum_rate:\n",
    "            lr = self.model.optimizer.lr\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, new_lr)\n",
    "            lr = self.model.optimizer.lr\n",
    "        print(K.eval(lr))\n",
    "\n",
    "# the learning rate decay in each batch end\n",
    "# and print the learning rate in each epoch end\n",
    "# beside, if the learning rate has been reduced to a minimum  times, this process stops\n",
    "class lr_minimum(keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, log=[]):\n",
    "        global Hdecay, _epoch, _batch_size\n",
    "        iterations = batch + _epoch * 1000.0 / _batch_size\n",
    "        print('iterations:', iterations)\n",
    "\n",
    "        new_lr = initial_lr * 1.0 / (1.0 + Hdecay * iterations)\n",
    "        print('The New_lr:', new_lr)\n",
    "        if initial_lr / new_lr > lr_minimum_rate:\n",
    "            K.set_value(self.model.optimizer.lr, initial_lr/lr_minimum_rate)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, new_lr)\n",
    "    def on_epoch_end(self, epoch, log=[]):\n",
    "        lr = self.model.optimizer.lr\n",
    "        global _epoch\n",
    "        _epoch += 1\n",
    "        print('Each epoch, the lr is', K.eval(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Comparison between two ways of decay\n",
    "Updating the learning rate after each eopch will avoid it decaying too fast, although it make the stepsize discontinuous. For very large volume of training data set, we don't suggest you use decay by batch because the learning rate can decay to 0 after just several epochs. Through the comparsion between using decay every batch (upper panel) and decay every epoch(lower panel), we choose the latter one because it can fit data better though it might be overfitting.\n",
    "\n",
    "<img src=\"figures/loss_byBatch_VS_byEpoch.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test different values of decay\n",
    "According to the formula above, larger value of decay will make learning rate decrease faster. Make sure your learning rate is not decaying too fast, so that the optimizer have the potential to arrive the global minimum. Here we show comparison of using three different decay rates (0.1, 0.01, 0.001), where the decay = 0.1 makes learning rate decrease too fast. Using decay = 0.01 or 0.001 enable the network to fit the training data better.\n",
    "\n",
    "<img src=\"figures/loss_v2_decay_0.1-0.01-0.001.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool functions on loss computing\n",
    "transform_to_coordinate function is to transform the predictive location information (middle_point_x, middle_point_y, width_of_image, height_of image) to a pair (top, left, bottom, right)\n",
    "\n",
    "Checking_if_object function is due to only knowing the location of object, we have to compute which grid the middle point of object is situated in.  \n",
    "\n",
    "return_coordinates is to transform the coordinates in the grid of a image to the coordinates in the whole images. The transformed rule is: \n",
    "a coordinate in the whole image = a coordinate in the one grid * the size of grid + the original point in this grid.   \n",
    "Both width and height of a grid are 64, which is the area where one point in the last feature map can be impacted in the initial figure.\n",
    "\n",
    "\n",
    "At here, the one of improvements of sliding window technique is we don't separately throw slide windows into the neural networks, because this method is doing many overlapping compuation. Instead, we implement the sliding window method convolutionally[1], which reduces the compuating at the overlapping areas between two sliding windows.  \n",
    "[1] Sermanet P, Eigen D, Zhang X, et al. Overfeat: Integrated recognition, localization and detection using convolutional networks[J]. arXiv preprint arXiv:1312.6229, 2013.  \n",
    "<img src=\"figures/Convoluational implementation.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" width=\"800\"/>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_coordinate(x, y, w, h):\n",
    "    x1 = x - K.cast(w / 2, 'float32')\n",
    "    y1 = y - K.cast(h / 2, 'float32')\n",
    "    x2 = x + K.cast(w / 2, 'float32')\n",
    "    y2 = y + K.cast(h / 2, 'float32')\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def Checking_if_object(x1_window, y1_window, x2_window, y2_window, x_max_true, x_min_true, y_max_true, y_min_true):\n",
    "    x_middle_true = (x_max_true + x_min_true)/2.0\n",
    "    y_middle_true = (y_max_true + y_min_true)/2.0\n",
    "    matching_x = tf.logical_and(K.greater_equal(x=x_middle_true, y=x1_window), K.greater_equal(x=x2_window, y= x_middle_true))\n",
    "    matching_y = tf.logical_and(K.greater_equal(x=y_middle_true, y=y1_window), K.greater_equal(x=y2_window, y= y_middle_true))\n",
    "    matching = tf.logical_and(matching_x, matching_y)\n",
    "    return matching\n",
    "\n",
    "# predictive middle_point x abd y should be within the range from 0 to 1.\n",
    "# predictive w and h should be the ratio bewteen actual length and grid size\n",
    "# Due to grid size is 64 by 64, and the image is 640 by 480, therefore, the ratio is not more than 10\n",
    "def return_coordinates(y_pred):\n",
    "    global _epsilon\n",
    "    xpred = y_pred[:, :, :, 1]\n",
    "    xpred = tf.clip_by_value(t=xpred, clip_value_min = 0 + _epsilon, clip_value_max = 1 - _epsilon)\n",
    "    xpred = K.cast(xpred, 'float32')\n",
    "    xpred = xpred * 64 + np.arange(0, 608, 32).reshape(19, 1)\n",
    "    ypred = y_pred[:, :, :, 2]\n",
    "    ypred = tf.clip_by_value(t=ypred, clip_value_min = 0 + _epsilon, clip_value_max = 1 - _epsilon)\n",
    "    ypred = K.cast(ypred, 'float32')\n",
    "    ypred = ypred * 64 + np.arange(0, 417, 32).reshape(1, 14)\n",
    "    wpred = y_pred[:, :, :, 3] * 64 * 10\n",
    "    wpred = K.clip(x=wpred, max_value=640, min_value=50)\n",
    "    hpred = y_pred[:, :, :, 4] * 64 * 10\n",
    "    hpred = K.clip(x=hpred, max_value=480, min_value=50)\n",
    "    return [xpred, ypred, wpred, hpred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tranforming the coordinate from a slide window to the image\n",
    "<img style=\"display: block; margin: 0 auto;\"\n",
    "     src=\"figures/transforming the coordinates from slide window to image.PNG\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "The two different loss function, Loss_v2 and Loss_v3, are custom loss function to compute the total loss among three types, location, object, classes. \n",
    "The difference between Loss_v2 and Loss_v3 is that we apply an accelerator on classification loss and object loss. The insight is from Retina Network[2]  \n",
    "\n",
    "By analysizing the consequences, we find out the classifier is easier to find out the background and hard to recognize the object that we are interested in. Therefore, the most of cases is to build up a network called Region proposal network to search the area that we are probabily interested in. However, it brings up numerous computations, thus the paper[2] comes up with an idea that by setting different important factors on right classified results and mistakenly classified results, the attention of the network are forced to transfer to the hard training set, and does not care about right classified images. It will speed up the convergence.  \n",
    "Besides, the important factor on Object Loss are highest than the other two because at the end, the scores of each prediction are more relevant with the object detected confidence.\n",
    "\n",
    "[2] Lin T Y, Goyal P, Girshick R, et al. Focal loss for dense object detection[J]. IEEE transactions on pattern analysis and machine intelligence, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss_v2(y_true, y_pred):\n",
    "    # obtaining the predictive confidence on object detection Pc_pred and preprocessing it.\n",
    "    Pc_pred = y_pred[:, :, :, 0]\n",
    "    Pc_pred = K.cast(Pc_pred, 'float32')\n",
    "    global _epsilon\n",
    "    Pc_pred = tf.clip_by_value(t=Pc_pred, clip_value_min = _epsilon, clip_value_max = 1 - _epsilon)\n",
    "    \n",
    "    #transforming the coordinates from a grid to the whole image\n",
    "    #and obtaining the actual coordinates in the whole images\n",
    "    xpred, ypred, wpred, hpred = return_coordinates(y_pred)\n",
    "    x1_pred, y1_pred, x2_pred, y2_pred = transform_to_coordinate(xpred, ypred, wpred, hpred)\n",
    "    \n",
    "    #obtaining the predictive classes and actual classes\n",
    "    C_Class_Array = y_pred[:, :, :, 5:]\n",
    "    x_max_true = y_true[:, :, :, 0]\n",
    "    x_min_true = y_true[:, :, :, 1]\n",
    "    y_max_true = y_true[:, :, :, 2]\n",
    "    y_min_true = y_true[:, :, :, 3]\n",
    "    C_index_true = y_true[:, :, :, 7:]\n",
    "    C_index_true = K.cast(C_index_true, dtype='float32')\n",
    "\n",
    "    #obtaining which grid is having the middle_point_Object \n",
    "    #and only in this grid, we compute location loss and classification loss, and in the rest of grid, we only care about object loss\n",
    "    X_matrix = np.ndarray((19, 14, 2), dtype='float32')\n",
    "    X_matrix[:, :, 0] = np.arange(0, 608, 32).reshape(19, 1)\n",
    "    X_matrix[:, :, 1] = np.arange(0, 417, 32).reshape(1, 14)\n",
    "    \n",
    "    x1_window = X_matrix[:, :, 0]\n",
    "    y1_window = X_matrix[:, :, 1]\n",
    "    x2_window = X_matrix[:, :, 0] + 64\n",
    "    y2_window = X_matrix[:, :, 1] + 64\n",
    "\n",
    "    matching = Checking_if_object(x1_window, y1_window, x2_window, y2_window, x_max_true, x_min_true,\n",
    "                                  y_max_true, y_min_true)\n",
    "    mat = K.cast(matching, 'float32')\n",
    "    \n",
    "    #compute the classification loss and put an acceleator on it\n",
    "    #the loss = (1 - p) * entropy(p) * mat\n",
    "    #p stands for the predictive probabilities of classes\n",
    "    #mat informs if there is an object in this grid\n",
    "    C_Class_Array = tf.clip_by_value(t=C_Class_Array, clip_value_min = _epsilon, clip_value_max = 1 - _epsilon)\n",
    "    Classification_loss = categorical_crossentropy(y_true= C_index_true, y_pred= C_Class_Array)\n",
    "\n",
    "    Classification_loss = K.reshape(x=Classification_loss, shape=(-1, 19, 14, 1))\n",
    "\n",
    "    Classification_loss  = (1 - C_Class_Array) * C_index_true * Classification_loss * weight_Classification_loss\n",
    "    \n",
    "    #compute location loss    \n",
    "    Localization_loss = weight_Localization_loss * mat * (K.square(x1_pred - x_min_true) + K.square(x2_pred - x_max_true) + K.square(\n",
    "        y1_pred - y_min_true) + K.square(y2_pred - y_max_true))\n",
    "    \n",
    "    #also put an acceleator\n",
    "    # loss = (1 - Pc) * entropy(Pc) * mat + (1 - mat) * Pc * entropy(1-Pc)\n",
    "    Object_loss = -(1 - Pc_pred) * K.log(Pc_pred) * mat - (1 - mat) * K.log(1-Pc_pred) * Pc_pred\n",
    "    Object_loss = Object_loss * weight_Object_loss\n",
    "\n",
    "    Total_loss = K.mean(axis=-1, x= K.mean(axis=-1, x=Classification_loss)) + K.mean(axis=-1, x=Localization_loss) + K.mean(axis=-1, x=Object_loss)\n",
    "    Totalloss = K.mean(x=Total_loss, axis=-1)\n",
    "\n",
    "    return Totalloss\n",
    "\n",
    "\n",
    "def Loss_v3(y_true, y_pred):\n",
    "    # obtaining the predictive confidence on object detection Pc_pred and preprocessing it.\n",
    "    Pc_pred = y_pred[:, :, :, 0]\n",
    "    Pc_pred = K.cast(Pc_pred, 'float32')\n",
    "    \n",
    "    #transforming the coordinates from a grid to the whole image\n",
    "    #and obtaining the actual coordinates in the whole images\n",
    "    xpred, ypred, wpred, hpred = return_coordinates(y_pred)\n",
    "    x1_pred, y1_pred, x2_pred, y2_pred = transform_to_coordinate(xpred, ypred, wpred, hpred)\n",
    "    \n",
    "    #obtaining the predictive classes and actual classes\n",
    "    C_Class_Array = y_pred[:, :, :, 5:]\n",
    "    x_max_true = y_true[:, :, :, 0]\n",
    "    x_min_true = y_true[:, :, :, 1]\n",
    "    y_max_true = y_true[:, :, :, 2]\n",
    "    y_min_true = y_true[:, :, :, 3]\n",
    "    C_index_true = y_true[:, :, :, 7:]\n",
    "    C_index_true = K.cast(C_index_true, dtype='float32')\n",
    "    \n",
    "    #obtaining which grid is having the middle_point_Object \n",
    "    #and only in this grid, we compute location loss and classification loss, and in the rest of grid, we only care about object loss   \n",
    "    X_matrix = np.ndarray((19, 14, 2), dtype='float32')\n",
    "    \n",
    "    X_matrix[:, :, 0] = np.arange(0, 608, 32).reshape(19, 1)\n",
    "    X_matrix[:, :, 1] = np.arange(0, 417, 32).reshape(1, 14)\n",
    "    \n",
    "    x1_window = X_matrix[:, :, 0]\n",
    "    y1_window = X_matrix[:, :, 1]\n",
    "    x2_window = X_matrix[:, :, 0] + 64\n",
    "    y2_window = X_matrix[:, :, 1] + 64\n",
    "\n",
    "    matching = Checking_if_object(x1_window, y1_window, x2_window, y2_window, x_max_true, x_min_true,\n",
    "                                  y_max_true, y_min_true)\n",
    "    mat = K.cast(matching, 'float32')\n",
    "   \n",
    "    #compute the classification loss and put an acceleator on it\n",
    "    #the loss = entropy(p) * mat\n",
    "    #p stands for the predictive probabilities of classes\n",
    "    #mat informs if there is an object in this grid\n",
    "    global _epsilon\n",
    "    \n",
    "    C_Class_Array = tf.clip_by_value(t=C_Class_Array, clip_value_min = _epsilon, clip_value_max = 1 - _epsilon)\n",
    "    \n",
    "    #compute location loss    \n",
    "    Classification_loss = categorical_crossentropy(y_true= C_index_true, y_pred= C_Class_Array) * weight_Classification_loss\n",
    "\n",
    "    Localization_loss = weight_Localization_loss * mat * (K.square(x1_pred - x_min_true) + K.square(x2_pred - x_max_true) + K.square(\n",
    "        y1_pred - y_min_true) + K.square(y2_pred - y_max_true))\n",
    "    \n",
    "    #also put an acceleator\n",
    "    #loss = mat * square(1 - Pc_pred) + (1 - mat) * square(Pc_pred)\n",
    "    Object_loss = weight_Object_loss * (mat * K.square(1 - Pc_pred) + (1 - mat) * K.square(Pc_pred))\n",
    "\n",
    "    Total_loss = K.mean(axis=-1, x=Classification_loss) + K.mean(axis=-1, x=Localization_loss) + K.mean(axis=-1, x=Object_loss)\n",
    "    Totalloss = K.mean(x=Total_loss, axis=-1)\n",
    "\n",
    "    return Totalloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compare the performance of minimizing loss_v2 and loss_v3\n",
    "From the figures below, we can easily find out the the convergence of loss v2 is more spped than loss function v3.   \n",
    "It proves that our insight is correct. By setting a small weight to right classified results and a big weight to wrong classified results, the network is forced to focus on hard classified samples, which speeds up the convergence.   \n",
    "<img src=\"figures/loss_v2_VS_loss_v3.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 5px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Utility tool for picking up the best prediction on each image\n",
    "This function is to pick up the relatively best five predictive boxes among all bounding boxes in each image.  \n",
    "Firstly, each predictive box has a score that is equal to the highest score on all classes.   \n",
    "And we directly pick up the five predictive boxes that have the 5 highest scores as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_consequences(results):\n",
    "    #########################################\n",
    "    global _batch_size\n",
    "    _batch_size = setting['batch_size']\n",
    "    #########################################\n",
    "    \n",
    "    # Obtain the Probability confidence\n",
    "    Pc = results[:, :, :, 0]\n",
    "    Pc = K.reshape(x = Pc, shape=(-1, 19, 14, 1))\n",
    "    \n",
    "    # Transforming the middle_point corrdinates with width and height of bounding boxes to \n",
    "    # the top-left and bottom-right coordinates in bounding boxes with original point is the top-left image\n",
    "    x ,y ,w ,h = return_coordinates(y_pred=results)\n",
    "    x = K.reshape(x=x, shape=(-1, 19, 14, 1))\n",
    "    y = K.reshape(x=y, shape=(-1, 19, 14, 1))\n",
    "    w = K.reshape(x=w, shape=(-1, 19, 14, 1))\n",
    "    h = K.reshape(x=h, shape=(-1, 19, 14, 1))\n",
    "    Boxes = K.concatenate([x, y, w, h], axis=-1)\n",
    "    \n",
    "    # Obtain the Classes Prediction\n",
    "    Class = results[:, :, :, 5:]\n",
    "    \n",
    "    # Compute the scores for all classes in one bounding box\n",
    "    Box_scores = Pc * Class\n",
    "    \n",
    "    # Picking the best as the scores in this bounding box\n",
    "    Box_classes = K.argmax(Box_scores, axis=-1)\n",
    "    Box_class_scores = K.max(Box_scores, axis=-1)\n",
    "    Box_classes = K.reshape(x=Box_classes, shape=(_batch_size, -1))\n",
    "    Box_class_scores = K.reshape(x=Box_class_scores, shape=(_batch_size, -1))\n",
    "    Boxes = K.reshape(x=Boxes, shape=(_batch_size, -1, 4))\n",
    "    \n",
    "    # Picking up the top five bounding boxes as the output\n",
    "    # Finding out the indices and catch the value by gather function\n",
    "    TOPK = tf.nn.top_k(input=Box_class_scores, k=5)\n",
    "    indices = TOPK.indices\n",
    "    temp = K.zeros(indices.get_shape(), dtype='int32')\n",
    "    tmp = K.arange(0, _batch_size, 1, dtype='int32')\n",
    "    tmp = K.reshape(x=tmp, shape=(_batch_size, -1))\n",
    "    temp = temp + tmp\n",
    "    indices = tf.stack([temp, indices], axis= 2)\n",
    "    scores = tf.gather_nd(params=Box_class_scores, indices=indices)\n",
    "    boxes = tf.gather_nd(params=Boxes, indices=indices)\n",
    "    classes = tf.gather_nd(params=Box_classes, indices=indices)\n",
    "    return boxes, classes, scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
